{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "944df786",
   "metadata": {},
   "source": [
    "### Topic Modelling \n",
    "\n",
    "Overall Research Questions:\n",
    "1) How do customers define 'good' service, and how does the new script shift those definitions?\n",
    "2) What aspects of service (clarity, empathy, agent personality) drive variance in sentiment?\n",
    "3) Does the new script systematically change perceptions or emotional tone, particularly for high-value segments like VOLT?\n",
    "\n",
    "What are the best topic modelling approaches given the above?\n",
    "\n",
    "Topic modelling is most relevant to Q1, but relates to Q3 as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251166c7",
   "metadata": {},
   "source": [
    "#### load the data/packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d138d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main dataset loaded: (582, 15)\n",
      "VOLT customers: 241\n",
      "Non-VOLT customers: 341\n",
      "Treatment group: 247\n",
      "Control group: 335\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../scripts/text_preprocessing.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m exec(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../scripts/setup.py\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mread()) \u001b[38;5;66;03m# load our data/packages\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m exec(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../scripts/text_preprocessing.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mread()) \u001b[38;5;66;03m# load text preprocessing functions - format as module later on\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../scripts/text_preprocessing.py'"
     ]
    }
   ],
   "source": [
    "\n",
    "exec(open('../scripts/setup.py').read()) # load our data/packages\n",
    "# Text preprocessing functions are already defined in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "587549c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GROUP</th>\n",
       "      <th>VOLT_FLAG</th>\n",
       "      <th>SURVEY_ID</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>LTR_COMMENT</th>\n",
       "      <th>PRIMARY_REASON</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>CONNECTION_TIME</th>\n",
       "      <th>SALES_PERSON_SAT</th>\n",
       "      <th>SALES_FRIENDLY_SAT</th>\n",
       "      <th>COMMINICATION_SAT</th>\n",
       "      <th>FIRST_BILL_SAT</th>\n",
       "      <th>AGENT_KNOWLEDGE</th>\n",
       "      <th>VOLT_FLAG_BINARY</th>\n",
       "      <th>TREATMENT_BINARY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>352240580</td>\n",
       "      <td>10</td>\n",
       "      <td>Good package</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>control</td>\n",
       "      <td>yes</td>\n",
       "      <td>351664275</td>\n",
       "      <td>10</td>\n",
       "      <td>Very good customer service</td>\n",
       "      <td>Customer Service,General,UK Legacy</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>control</td>\n",
       "      <td>yes</td>\n",
       "      <td>351723391</td>\n",
       "      <td>10</td>\n",
       "      <td>So far so good. Charlie was very efficient and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>351702901</td>\n",
       "      <td>10</td>\n",
       "      <td>Great communication</td>\n",
       "      <td>Customer Service,General,UK Legacy</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>control</td>\n",
       "      <td>yes</td>\n",
       "      <td>352243612</td>\n",
       "      <td>10</td>\n",
       "      <td>Because Chris was amazing when she contacted m...</td>\n",
       "      <td>Customer Service,UK Legacy</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      GROUP VOLT_FLAG  SURVEY_ID  SCORE                                        LTR_COMMENT                      PRIMARY_REASON      MONTH  CONNECTION_TIME  SALES_PERSON_SAT  SALES_FRIENDLY_SAT  COMMINICATION_SAT  FIRST_BILL_SAT  AGENT_KNOWLEDGE  VOLT_FLAG_BINARY  TREATMENT_BINARY\n",
       "45  control       NaN  352240580     10                                       Good package                                 NaN 2023-03-01               10                10                   8                 10              10               10                 0                 0\n",
       "46  control       yes  351664275     10                         Very good customer service  Customer Service,General,UK Legacy 2023-03-01               10                10                  10                 10              10               10                 1                 0\n",
       "47  control       yes  351723391     10  So far so good. Charlie was very efficient and...                                 NaN 2023-03-01               10              <NA>                  10                 10              10               10                 1                 0\n",
       "48  control       NaN  351702901     10                                Great communication  Customer Service,General,UK Legacy 2023-03-01                9                10                  10                 10              10               10                 0                 0\n",
       "49  control       yes  352243612     10  Because Chris was amazing when she contacted m...          Customer Service,UK Legacy 2023-03-01               10              <NA>                  10                 10              10               10                 1                 0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f090f9d",
   "metadata": {},
   "source": [
    "#### Let's randomly sample some text responses to build a suitable approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "689d6891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: The gentleman who dealt us was so helpful and friendly.. he deserves a lot of credit. Very nice man..\n",
      "\n",
      "Sample 2: Very prompt response\n",
      "\n",
      "Sample 3: Good communication and very helpful\n",
      "\n",
      "Sample 4: Your customer service is awful and you really need to ditch the overseas call centers. Kindness and understanding in the voice go a long way. You can feel the contempt in operator voices (sniggering and laughing when you say you cannot understnd what they are saying - feels intentional) and cannot quite get all of the words due to very strong accents. Your only saving grace is the physical connection and stability of that. Thankfully, because connection quality is good I rarely (if ever - Thank Goodness) have to contact your call centers. Would not touch with a barge pole otherwise. Take a look at Now Broadband whos operators are absolutely marvellous. Lessons learned or brushed under the carpet? Haha\n",
      "\n",
      "Sample 5: Excellent customer service\n",
      "\n",
      "Sample 6: Simple process with very helpful staff.\n",
      "\n",
      "Sample 7: On the 13th March I ordered with Supanet, I contacted them again on the 3rd April to found out when I could expect my broadband, they had no answers, I immediately cancelled the order and contacted company sales, I spoke with a very helpful gentleman who informed me company would have me up and running in 2 days the 5th April, I immediately confirmed my order. Today is Wednesday 5th April I have received my parcel from company and my broadband is all connected, well done company, excellent service\n",
      "\n",
      "Sample 8: The team who came out were friendly and explained all they needed to do. Also clear about the fact one of them was a trainee but still provided an excellent customer service\n",
      "\n",
      "Sample 9: Very good price and service\n",
      "\n",
      "Sample 10: I needed my SIM urgently and was told I will get it by Wednesday even though I called on Monday evening. I got my SIM on Wednesday as I was told I would.\n",
      "\n",
      "Sample 11: Basically a waste of time. They can¬\"t install anything. They weren¬\"t interested in trying to help set it up. Second chap gave me some information telling me I would have to run cables outside my house and all over the inside as well. Not impressed. I was also told someone would be in touch about there efforts that has not happened. I have now cancelled my set up fo direct debit\n",
      "\n",
      "Sample 12: He was very friendly and explained things well\n",
      "\n",
      "Sample 13: Easy to change over & friendly & professional call taker !\n",
      "\n",
      "Sample 14: Good customer service, polite Staff\n",
      "\n",
      "Sample 15: Very happy with Maria from customer service centre and Stephen the technician.Both were very helpful and understanding\n",
      "\n",
      "Sample 16: I have had a bad experience with your customer services I am not proceeding with installation\n",
      "\n",
      "Sample 17: I had a massive drama with shell energy moving home. I has very bad customer service, I spoke to company and within 2 days had active broadband in my house. Something She¬\"ll couldn¬\"t do after 3 hrs on the phone\n",
      "\n",
      "Sample 18: Great benefits but pricey\n",
      "\n",
      "Sample 19: They were proactive and called me, as I had added to the Basket. Saved me a call. The next day I filled in the request for information outside our house for cabling. The contractor arrived a few hours later to fit the cable. Unbelievable service.\n",
      "\n",
      "Sample 20: Very friendly customer service. Clear explanation of what is included.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# randomly print a sample from non-missing LTR_COMMENT in df\n",
    "sample_size = 20\n",
    "sample = df[df['LTR_COMMENT'].notna()]['LTR_COMMENT'].sample(n=sample_size, random_state=45).tolist()\n",
    "for i, comment in enumerate(sample, 1):\n",
    "    print(f\"Sample {i}: {comment}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c8fdee",
   "metadata": {},
   "source": [
    "Comments comprise long and short responses. Topic modelling is more nuanced for longer responses, even though short responses can reflect similar (but more simple) themes. \n",
    "A suitable first step is to clean the responses to remove punctuation and unusual characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba3f4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the following as a module later on\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)  \n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "def clean_text(text, return_tokens=False, min_word_length=2, language='english'):\n",
    "    \"\"\"\n",
    "    Clean a single text string for NLP analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Input text string to clean\n",
    "    return_tokens : bool, default False\n",
    "        If True, returns list of tokens; if False, returns cleaned text string\n",
    "    min_word_length : int, default 2\n",
    "        Minimum word length to keep\n",
    "    language : str, default 'english'\n",
    "        Language for stopwords\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str or list\n",
    "        Cleaned text string or list of tokens\n",
    "    \"\"\"\n",
    "    # Initialize components\n",
    "    stop_words = set(stopwords.words(language))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Handle missing/empty text\n",
    "    if pd.isna(text) or not str(text).strip():\n",
    "        return [] if return_tokens else ''\n",
    "    \n",
    "    # Convert to string and lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove punctuation and normalize whitespace\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Tokenize, filter stopwords and short words\n",
    "    tokens = [word for word in text.split() \n",
    "              if word not in stop_words and len(word) >= min_word_length]\n",
    "    \n",
    "    # Lemmatize tokens\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    return tokens if return_tokens else ' '.join(tokens)\n",
    "\n",
    "def clean_text_series(series, return_tokens=False, min_word_length=2, language='english'):\n",
    "    \"\"\"\n",
    "    Apply text cleaning to a pandas Series.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    series : pandas.Series\n",
    "        Series containing text data\n",
    "    return_tokens : bool, default False\n",
    "        If True, returns list of tokens; if False, returns cleaned text string\n",
    "    min_word_length : int, default 2\n",
    "        Minimum word length to keep\n",
    "    language : str, default 'english'\n",
    "        Language for stopwords\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.Series\n",
    "        Series with cleaned text\n",
    "    \"\"\"\n",
    "    return series.apply(lambda x: clean_text(x, return_tokens, min_word_length, language))\n",
    "\n",
    "def add_cleaned_text_columns(df, text_columns, suffix='_clean', \n",
    "                           min_word_length=2, language='english', \n",
    "                           add_tokens=True, add_word_count=True):\n",
    "    \"\"\"\n",
    "    Add cleaned text columns to dataframe for multiple text columns.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataframe\n",
    "    text_columns : str or list\n",
    "        Column name(s) containing text to clean\n",
    "    suffix : str, default '_clean'\n",
    "        Suffix for cleaned text columns\n",
    "    min_word_length : int, default 2\n",
    "        Minimum word length to keep\n",
    "    language : str, default 'english'\n",
    "        Language for stopwords\n",
    "    add_tokens : bool, default True\n",
    "        Whether to add tokenized version\n",
    "    add_word_count : bool, default True\n",
    "        Whether to add word count column\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Dataframe with additional cleaned text columns\n",
    "    \"\"\"\n",
    "    df_result = df.copy()\n",
    "    \n",
    "    # Ensure text_columns is a list\n",
    "    if isinstance(text_columns, str):\n",
    "        text_columns = [text_columns]\n",
    "    \n",
    "    for col in text_columns:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        # Add cleaned text column\n",
    "        clean_col = f\"{col}{suffix}\"\n",
    "        df_result[clean_col] = clean_text_series(\n",
    "            df[col], return_tokens=False, \n",
    "            min_word_length=min_word_length, language=language\n",
    "        )\n",
    "        \n",
    "        # Add tokenized version\n",
    "        if add_tokens:\n",
    "            tokens_col = f\"{col}_tokens\"\n",
    "            df_result[tokens_col] = clean_text_series(\n",
    "                df[col], return_tokens=True,\n",
    "                min_word_length=min_word_length, language=language\n",
    "            )\n",
    "        \n",
    "        # Add word count\n",
    "        if add_word_count:\n",
    "            count_col = f\"{col}_word_count\"\n",
    "            df_result[count_col] = df_result[clean_col].str.split().str.len().fillna(0)\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "# Convenience function for common preprocessing pipeline\n",
    "def preprocess_text_for_modeling(df, text_columns, min_word_length=2, \n",
    "                                language='english', filter_empty=True):\n",
    "    \"\"\"\n",
    "    Complete preprocessing pipeline for text modeling.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataframe\n",
    "    text_columns : str or list\n",
    "        Column name(s) containing text to clean\n",
    "    min_word_length : int, default 2\n",
    "        Minimum word length to keep\n",
    "    language : str, default 'english'\n",
    "        Language for stopwords\n",
    "    filter_empty : bool, default True\n",
    "        Whether to add flag for non-empty text\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Preprocessed dataframe ready for modeling\n",
    "    \"\"\"\n",
    "    # Clean text\n",
    "    df_clean = add_cleaned_text_columns(\n",
    "        df, text_columns, min_word_length=min_word_length, \n",
    "        language=language, add_tokens=True, add_word_count=True\n",
    "    )\n",
    "    \n",
    "    # Add flags for non-empty text\n",
    "    if filter_empty:\n",
    "        if isinstance(text_columns, str):\n",
    "            text_columns = [text_columns]\n",
    "        \n",
    "        for col in text_columns:\n",
    "            clean_col = f\"{col}_clean\"\n",
    "            flag_col = f\"has_{col}\"\n",
    "            df_clean[flag_col] = (df_clean[clean_col].str.len() > 0)\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e077832f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ORIGINAL vs CLEANED COMMENTS ===\n",
      "\n",
      "--- Sample 1 ---\n",
      "ORIGINAL: Percy explained things clearly and understood from the start what I wanted. there was no hard sell. there was listening and understanding. top marks Percy and thank you\n",
      "CLEANED:  percy explained thing clearly understood start wanted hard sell listening understanding top mark percy thank\n",
      "--------------------------------------------------------------------------------\n",
      "--- Sample 2 ---\n",
      "ORIGINAL: Excellent service lovely representative Mathius\n",
      "CLEANED:  excellent service lovely representative mathius\n",
      "--------------------------------------------------------------------------------\n",
      "--- Sample 3 ---\n",
      "ORIGINAL: Very friendly staff and accommodating\n",
      "CLEANED:  friendly staff accommodating\n",
      "--------------------------------------------------------------------------------\n",
      "--- Sample 4 ---\n",
      "ORIGINAL: Very difficult to talk to anyone, very expensive, always an IT problem, too many calls, lots of mistakes took place with my name, dates leaving or moving in, misleading advertising in such that it appears cheaper than what it actually costs. Sorry if that is too negative, however this is an accurate reflection of company. You do however have fast and mostly reliable internet\n",
      "CLEANED:  difficult talk anyone expensive always problem many call lot mistake took place name date leaving moving misleading advertising appears cheaper actually cost sorry negative however accurate reflection company however fast mostly reliable internet\n",
      "--------------------------------------------------------------------------------\n",
      "--- Sample 5 ---\n",
      "ORIGINAL: Your customer service was so good to me\n",
      "CLEANED:  customer service good\n",
      "--------------------------------------------------------------------------------\n",
      "--- Sample 6 ---\n",
      "ORIGINAL: Perfect\n",
      "CLEANED:  perfect\n",
      "--------------------------------------------------------------------------------\n",
      "--- Sample 7 ---\n",
      "ORIGINAL: Very efficient and Friendly Service\n",
      "CLEANED:  efficient friendly service\n",
      "--------------------------------------------------------------------------------\n",
      "--- Sample 8 ---\n",
      "ORIGINAL: Jake the representative for company was simply above and beyond helpful and done everything for me with ease\n",
      "CLEANED:  jake representative company simply beyond helpful done everything ease\n",
      "--------------------------------------------------------------------------------\n",
      "--- Sample 9 ---\n",
      "ORIGINAL: Excellent service from the get go, the gent I spoke to on the phone, and the guy who did the installation were superb. I can¬\"t remember their name though.\n",
      "CLEANED:  excellent service get go gent spoke phone guy installation superb remember name though\n",
      "--------------------------------------------------------------------------------\n",
      "--- Sample 10 ---\n",
      "ORIGINAL: All requirements were met with courtesy and helpfulness and promptness. I was informed of all I needed to know.\n",
      "CLEANED:  requirement met courtesy helpfulness promptness informed needed know\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Simple side-by-side comparison of original vs cleaned comments\n",
    "sample_size = 10\n",
    "\n",
    "# Get sample of non-missing comments\n",
    "sample_df = df[df['LTR_COMMENT'].notna()].sample(n=sample_size, random_state=42)\n",
    "\n",
    "print(\"=== ORIGINAL vs CLEANED COMMENTS ===\\n\")\n",
    "\n",
    "for i, (idx, row) in enumerate(sample_df.iterrows(), 1):\n",
    "    print(f\"--- Sample {i} ---\")\n",
    "    print(f\"ORIGINAL: {row['LTR_COMMENT']}\")\n",
    "    print(f\"CLEANED:  {row['LTR_COMMENT_CLEAN']}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a7e106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GROUP</th>\n",
       "      <th>VOLT_FLAG</th>\n",
       "      <th>SURVEY_ID</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>LTR_COMMENT</th>\n",
       "      <th>PRIMARY_REASON</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>CONNECTION_TIME</th>\n",
       "      <th>SALES_PERSON_SAT</th>\n",
       "      <th>SALES_FRIENDLY_SAT</th>\n",
       "      <th>COMMINICATION_SAT</th>\n",
       "      <th>FIRST_BILL_SAT</th>\n",
       "      <th>AGENT_KNOWLEDGE</th>\n",
       "      <th>VOLT_FLAG_BINARY</th>\n",
       "      <th>TREATMENT_BINARY</th>\n",
       "      <th>LTR_COMMENT_CLEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>352240580</td>\n",
       "      <td>10</td>\n",
       "      <td>Good package</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>good package</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>control</td>\n",
       "      <td>yes</td>\n",
       "      <td>351664275</td>\n",
       "      <td>10</td>\n",
       "      <td>Very good customer service</td>\n",
       "      <td>Customer Service,General,UK Legacy</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>good customer service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>control</td>\n",
       "      <td>yes</td>\n",
       "      <td>351723391</td>\n",
       "      <td>10</td>\n",
       "      <td>So far so good. Charlie was very efficient and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>far good charlie efficient helpful let hope co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>351702901</td>\n",
       "      <td>10</td>\n",
       "      <td>Great communication</td>\n",
       "      <td>Customer Service,General,UK Legacy</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>great communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>control</td>\n",
       "      <td>yes</td>\n",
       "      <td>352243612</td>\n",
       "      <td>10</td>\n",
       "      <td>Because Chris was amazing when she contacted m...</td>\n",
       "      <td>Customer Service,UK Legacy</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>chris amazing contacted put detail online</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      GROUP VOLT_FLAG  SURVEY_ID  SCORE                                        LTR_COMMENT                      PRIMARY_REASON      MONTH  CONNECTION_TIME  SALES_PERSON_SAT  SALES_FRIENDLY_SAT  COMMINICATION_SAT  FIRST_BILL_SAT  AGENT_KNOWLEDGE  VOLT_FLAG_BINARY  TREATMENT_BINARY                                  LTR_COMMENT_CLEAN\n",
       "45  control       NaN  352240580     10                                       Good package                                 NaN 2023-03-01               10                10                   8                 10              10               10                 0                 0                                       good package\n",
       "46  control       yes  351664275     10                         Very good customer service  Customer Service,General,UK Legacy 2023-03-01               10                10                  10                 10              10               10                 1                 0                              good customer service\n",
       "47  control       yes  351723391     10  So far so good. Charlie was very efficient and...                                 NaN 2023-03-01               10              <NA>                  10                 10              10               10                 1                 0  far good charlie efficient helpful let hope co...\n",
       "48  control       NaN  351702901     10                                Great communication  Customer Service,General,UK Legacy 2023-03-01                9                10                  10                 10              10               10                 0                 0                                great communication\n",
       "49  control       yes  352243612     10  Because Chris was amazing when she contacted m...          Customer Service,UK Legacy 2023-03-01               10              <NA>                  10                 10              10               10                 1                 0          chris amazing contacted put detail online"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
